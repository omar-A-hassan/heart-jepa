{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart-JEPA Pipeline\n",
    "\n",
    "1. Clone & Setup\n",
    "2. Download data\n",
    "3. Pretrain (self-supervised)\n",
    "4. Fine-tune (classification/segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Clone & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo\n",
    "!git clone https://github.com/omar-A-hassan/heart-jepa.git\n",
    "%cd heart-jepa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install git+https://github.com/rbalestr-lab/lejepa.git\n!pip install -e \".[train]\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download PhysioNet 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data/physionet2016\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for subset in ['a', 'b', 'c', 'd', 'e', 'f']:\n",
    "    output_dir = data_dir / f\"training-{subset}\"\n",
    "    if output_dir.exists() and any(output_dir.glob(\"*.wav\")):\n",
    "        print(f\"training-{subset}: exists\")\n",
    "        continue\n",
    "    print(f\"Downloading training-{subset}...\")\n",
    "    wfdb.dl_database(f\"challenge-2016/training-{subset}\", str(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "total = len(list(data_dir.glob(\"**/*.wav\")))\n",
    "print(f\"Total WAV files: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pretrain\n",
    "\n",
    "Self-supervised learning with SIGReg + Invariance loss. No labels needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pretraining\n",
    "!python scripts/train_pretrain.py \\\n",
    "    ++data_dir=data/physionet2016 \\\n",
    "    ++max_epochs=50 \\\n",
    "    ++batch_size=16 \\\n",
    "    ++save_dir=checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What Pretraining Produces\n",
    "\n",
    "| Component | What it learned | Used for |\n",
    "|-----------|-----------------|----------|\n",
    "| **Encoder** | Cardiac features | Backbone for downstream tasks |\n",
    "| **Projector** | 256-dim embeddings | Discard after pretraining |\n",
    "| **Heads** | Random init | Fine-tune for tasks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best checkpoint\n",
    "from pathlib import Path\n",
    "checkpoints = list(Path(\"checkpoints\").glob(\"heart-jepa-*.ckpt\"))\n",
    "if checkpoints:\n",
    "    latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Pretrained checkpoint: {latest}\")\n",
    "else:\n",
    "    print(\"No checkpoint found - run pretraining first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tune for Classification\n",
    "\n",
    "Train classification head: Normal vs Abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune classification (update checkpoint path)\n",
    "!python scripts/train_finetune.py \\\n",
    "    task=classification \\\n",
    "    ++data_dir=data/physionet2016 \\\n",
    "    ++pretrained_checkpoint=checkpoints/YOUR_CHECKPOINT.ckpt \\\n",
    "    ++freeze_encoder=true \\\n",
    "    ++finetune_epochs=20 \\\n",
    "    ++cls_num_classes=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tune for Segmentation\n",
    "\n",
    "Train segmentation head: S1, S2, Systole, Diastole, etc.\n",
    "\n",
    "**Pseudo-labels are auto-generated** from the PCG signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune segmentation (update checkpoint path)\n",
    "!python scripts/train_finetune.py \\\n",
    "    task=segmentation \\\n",
    "    ++data_dir=data/physionet2016 \\\n",
    "    ++pretrained_checkpoint=checkpoints/YOUR_CHECKPOINT.ckpt \\\n",
    "    ++freeze_encoder=true \\\n",
    "    ++finetune_epochs=30 \\\n",
    "    ++seg_num_classes=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Stage | Script | Data | Output |\n",
    "|-------|--------|------|--------|\n",
    "| Pretrain | `train_pretrain.py` | Unlabeled PCG | Encoder weights |\n",
    "| Fine-tune (cls) | `train_finetune.py task=classification` | Normal/Abnormal labels | Classification model |\n",
    "| Fine-tune (seg) | `train_finetune.py task=segmentation` | Auto pseudo-labels | Segmentation model |\n",
    "\n",
    "### Segmentation classes:\n",
    "0=Background, 1=S1, 2=Systole, 3=S2, 4=Diastole, 5=S3, 6=S4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}