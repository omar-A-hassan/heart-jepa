# Heart-JEPA Base Configuration
# Following LEJEPA training patterns with Hydra + Lightning

# Model
backbone: "vit_base_patch16_224"
pretrained: true
proj_dim: 256
hidden_dim: 2048
embed_dim: 768

# Segmentation head
seg_hidden_dim: 256
seg_num_classes: 7
seg_output_frames: 224

# Classification head
cls_hidden_dim: 256
cls_num_classes: 3
cls_dropout: 0.1

# SIGReg loss (using official LEJEPA)
bstat_name: "epps_pulley"
bstat_num_slices: 1000
bstat_t_max: 3.0
bstat_n_points: 17
bstat_lambda: 0.01  # SIGReg weight

# Invariance loss
invariance_weight: 1.0
invariance_temp: 0.1

# Data
data_dir: "data/physionet2016"
batch_size: 32
num_workers: 4
n_views: 4
sample_rate: 2000
duration: 5.0

# Spectrogram
n_fft: 512
hop_length: 64
n_mels: 128
fmin: 20
fmax: 500

# Training
max_epochs: 100
lr: 1e-4
weight_decay: 1e-5
warmup_epochs: 5

# Optimizer
optimizer: "adamw"
scheduler: "cosine"

# Device
accelerator: "auto"  # auto-detect MPS/CUDA/CPU
devices: 1
precision: 32

# Logging
wandb_project: null  # Set to enable WandB
wandb_entity: null
log_every_n_steps: 10
val_check_interval: 1.0

# Checkpointing
save_dir: "checkpoints"
save_top_k: 3

# Reproducibility
seed: 42

# Fine-tuning
task: "classification"  # or "segmentation"
pretrained_checkpoint: null  # Path to pretrained checkpoint
freeze_encoder: true
finetune_epochs: 30
finetune_lr: 1e-3
finetune_batch_size: 32

# Segmentation loss weights
seg_ce_weight: 0.5
seg_dice_weight: 0.5

defaults:
  - _self_
